{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "736b7648-7ccf-4d6f-9ed5-b5cae3742e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Text:\n",
      "It was the best of\n",
      "times, it was the worst\n",
      "of times, it was the age\n",
      "of wisdom, it was the\n",
      "age of foolishness...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import pytesseract\n",
    "\n",
    "# Path to Tesseract OCR executable (update path if needed)\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "# Load image\n",
    "image_path = 'C:test.png'\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Extract text\n",
    "extracted_text = pytesseract.image_to_string(image)\n",
    "print(\"Extracted Text:\")\n",
    "print(extracted_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc8ef4c3-156b-4745-b814-44872fbdbe96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Text:\n",
      "Tomorrow, and\n",
      "â€˜tomorrow, and\n",
      "tomorrow; creeps\n",
      "in this petty pace\n",
      "from day to day,\n",
      "until the last syll-\n",
      "able of recorded\n",
      "time. And all our\n",
      "yesterdays have\n",
      "lighted fools the\n",
      "way to dusty\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import pytesseract\n",
    "\n",
    "# Path to Tesseract OCR executable (update path if needed)\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "# Load image\n",
    "image_path = 'C:test2.png'\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Extract text\n",
    "extracted_text = pytesseract.image_to_string(image)\n",
    "print(\"Extracted Text:\")\n",
    "print(extracted_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee4e03f9-c89f-4898-8329-aedd52cc1f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyautogui is installed and ready to use.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import pyautogui\n",
    "    print(\"pyautogui is installed and ready to use.\")\n",
    "except ImportError:\n",
    "    print(\"pyautogui is not installed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c38dfaa1-2b13-4709-a695-42936ca67244",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pyautogui' has no attribute 'Position'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyautogui\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mpyautogui\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPosition\u001b[49m())\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'pyautogui' has no attribute 'Position'"
     ]
    }
   ],
   "source": [
    "import pyautogui\n",
    "\n",
    "print(pyautogui.Position())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45a8c30a-3153-49ab-a085-926067b8bf45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point(x=626, y=855)\n"
     ]
    }
   ],
   "source": [
    "import pyautogui\n",
    "\n",
    "print(pyautogui.position())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf3aaa2a-3bbb-498d-afcb-452b5fad3601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Screen size: Size(width=1920, height=1080)\n"
     ]
    }
   ],
   "source": [
    "import pyautogui\n",
    "\n",
    "# Test pyautogui\n",
    "screen_size = pyautogui.size()\n",
    "print(f\"Screen size: {screen_size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c937579f-5910-4d28-9f74-8337ee2beefa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Screen size: Size(width=1920, height=1080)\n"
     ]
    }
   ],
   "source": [
    "screen_size = pyautogui.size()\n",
    "print(f\"Screen size: {screen_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8083c2b6-4d0e-4d52-8865-887204066ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Screenshot saved as 'captured.png'\n"
     ]
    }
   ],
   "source": [
    "import pyautogui\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "# Capture screen\n",
    "screenshot = pyautogui.screenshot(region=(0, 0,1920,1080))  # x, y, width, height\n",
    "screenshot.save(\"captured.png\")\n",
    "\n",
    "# Verify if the screenshot is saved correctly\n",
    "print(\"Screenshot saved as 'captured.png'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aea175f9-1683-4c0c-8d9d-e183c97e791d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Text:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import pytesseract\n",
    "\n",
    "# Path to Tesseract OCR executable (update path if needed)\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "# Load image\n",
    "image_path = 'C:test3.jpeg'\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Extract text\n",
    "extracted_text = pytesseract.image_to_string(image)\n",
    "print(\"Extracted Text:\")\n",
    "print(extracted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b3b2731-502a-4551-9ff8-49e754b98d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TableList n=1>\n"
     ]
    }
   ],
   "source": [
    "import camelot\n",
    "\n",
    "# Replace 'example.pdf' with the path to a PDF file with tables\n",
    "tables = camelot.read_pdf('C:/example.pdf', pages='9')\n",
    "print(tables)\n",
    "tables[0].to_csv('Output.csv')  # Save the first table to a CSV file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fab7332-99e6-4a68-ad3b-4e7069288be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case 1: Text Extraction\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Choose an option: 1. Upload Image 2. Select Area on Screen:  1\n",
      "Enter the image file path:  C:\\test.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracted Text:\n",
      " It was the best of\n",
      "times, it was the worst\n",
      "of times, it was the age\n",
      "of wisdom, it was the\n",
      "age of foolishness...\n",
      "\n",
      "\n",
      "Case 2: Table Extraction\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the PDF file path:  C:\\example.pdf\n",
      "Choose an option: 1. Extract All Tables 2. Extract from Specific Page:  2\n",
      "Enter the page number:  9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 1 table(s) and saved to CSV.\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "import pyautogui\n",
    "import camelot\n",
    "\n",
    "# Path to Tesseract OCR executable (update this based on your system)\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "# --- Case 1: Extract Text from Image ---\n",
    "def extract_text_from_image(image_path=None, region=None):\n",
    "    \"\"\"\n",
    "    Extract text from an image file or a selected region on the screen.\n",
    "    :param image_path: Path to the image file (optional).\n",
    "    :param region: Tuple (x, y, width, height) for a screen region (optional).\n",
    "    :return: Extracted text as a string.\n",
    "    \"\"\"\n",
    "    if image_path:\n",
    "        # Load image from file\n",
    "        img = Image.open(image_path)\n",
    "    elif region:\n",
    "        # Capture specific region on the screen\n",
    "        screenshot = pyautogui.screenshot(region=region)\n",
    "        screenshot.save(\"selected_region.png\")\n",
    "        img = Image.open(\"selected_region.png\")\n",
    "    else:\n",
    "        raise ValueError(\"Either image_path or region must be provided.\")\n",
    "\n",
    "    # Extract text using Tesseract\n",
    "    extracted_text = pytesseract.image_to_string(img)\n",
    "    return extracted_text\n",
    "\n",
    "\n",
    "# --- Case 2: Extract Tables from PDF ---\n",
    "def extract_tables_from_pdf(pdf_path, page_number=None):\n",
    "    \"\"\"\n",
    "    Extract tables from a PDF file and save them to CSV.\n",
    "    :param pdf_path: Path to the PDF file.\n",
    "    :param page_number: Specific page number to extract tables from (optional).\n",
    "    :return: List of table data (or CSV files saved).\n",
    "    \"\"\"\n",
    "    if page_number:\n",
    "        tables = camelot.read_pdf(pdf_path, pages=str(page_number))\n",
    "    else:\n",
    "        tables = camelot.read_pdf(pdf_path, pages='all')\n",
    "\n",
    "    if not tables:\n",
    "        return \"No tables found in the specified PDF.\"\n",
    "\n",
    "    # Save each table to a CSV file\n",
    "    for i, table in enumerate(tables):\n",
    "        table.to_csv(f\"table_{i + 1}.csv\")\n",
    "\n",
    "    return f\"Extracted {len(tables)} table(s) and saved to CSV.\"\n",
    "\n",
    "\n",
    "# --- Example Usage ---\n",
    "if __name__ == \"__main__\":\n",
    "    # --- Case 1: Text Extraction ---\n",
    "    print(\"Case 1: Text Extraction\")\n",
    "    option = input(\"Choose an option: 1. Upload Image 2. Select Area on Screen: \")\n",
    "\n",
    "    if option == \"1\":\n",
    "        image_path = input(\"Enter the image file path: \")\n",
    "        text = extract_text_from_image(image_path=image_path)\n",
    "        print(\"\\nExtracted Text:\\n\", text)\n",
    "    elif option == \"2\":\n",
    "        print(\"Drag and select an area on the screen (example region: x=100, y=100, width=500, height=300).\")\n",
    "        x, y, width, height = map(int, input(\"Enter x, y, width, height: \").split())\n",
    "        text = extract_text_from_image(region=(x, y, width, height))\n",
    "        print(\"\\nExtracted Text from Selected Area:\\n\", text)\n",
    "\n",
    "    # --- Case 2: Table Extraction ---\n",
    "    print(\"\\nCase 2: Table Extraction\")\n",
    "    pdf_path = input(\"Enter the PDF file path: \")\n",
    "    option = input(\"Choose an option: 1. Extract All Tables 2. Extract from Specific Page: \")\n",
    "\n",
    "    if option == \"1\":\n",
    "        result = extract_tables_from_pdf(pdf_path)\n",
    "        print(result)\n",
    "    elif option == \"2\":\n",
    "        page_number = int(input(\"Enter the page number: \"))\n",
    "        result = extract_tables_from_pdf(pdf_path, page_number=page_number)\n",
    "        print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d8a238c-8ae2-4045-9163-f62b951b6cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose an option:\n",
      "1. Extract Text from Image\n",
      "2. Extract Tabular Data\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your choice (1 or 2):  1\n",
      "Upload an image file (enter the file path):  C:\\test2.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Choose an option:\n",
      "1. Extract text from the entire image\n",
      "2. Select a specific region\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your choice (1 or 2):  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drag and select an area on the screen (example region: x=100, y=100, width=500, height=300).\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter x, y, width, height:  0 0 1920 1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracted Text from Selected Region:\n",
      " alho\n",
      "\n",
      "Placement ) (DSA | INTERN\n",
      "\n",
      "minutes ago\n",
      "\n",
      "File Edit View Run Kemel Settings Help Trusted\n",
      "\n",
      "8B + XO 0O Â» mm C Â» Code â€œ Jupyterlab [7 # Python 3 (ipykernel) @ =\n",
      "print(rez<Lo YD oT <\n",
      "\n",
      "elif sub_choice\n",
      "# Extract tables from a specific page\n",
      "page_number = int(input(\"Enter the page number: \"))\n",
      "result = extract_tables_from_pdf(pdf_path, page_number=page_number)\n",
      "print (result)\n",
      "\n",
      "else:\n",
      "print(\"Invalid choice.\")\n",
      "\n",
      "else:\n",
      "\n",
      "print(\"Invalid choice. Please restart the program\n",
      "\n",
      "Choose an option:\n",
      "\n",
      "1. Extract Text from Image\n",
      "2. Extract Tabular Data\n",
      "Enter your choice (1 or 2):\n",
      "Upload an image file (enter the file path): C:\\test2.png\n",
      "\n",
      "Choose an option:\n",
      "\n",
      "1. Extract text from the entire image\n",
      "\n",
      "2. Select a specific region\n",
      "\n",
      "Enter your choice (1 or 2): 2\n",
      "\n",
      "Drag and select an area on the screen (example region: x=100, y=100, width=500, height=300).\n",
      "Enter x, y, width, height: [@ Â© 1920 1ese\n",
      "\n",
      "import pytesseract\n",
      "from PIL import Image, ImageTk\n",
      "import tkinter as tk\n",
      "\n",
      "from tkinter import filedialog\n",
      "import pyautogui\n",
      "\n",
      "import camelot\n",
      "\n",
      "# Path to Tesseract OCR executable (update this based on your system)\n",
      "\n",
      "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe' -\n",
      "ENG 332PM\n",
      "IN 1/22/2025\n",
      "\n",
      "a)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "import pyautogui\n",
    "import camelot\n",
    "\n",
    "# Path to Tesseract OCR executable (update this based on your system)\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "\n",
    "# --- Case 1: Extract Text from Image ---\n",
    "def extract_text_from_image(image_path=None, region=None):\n",
    "    \"\"\"\n",
    "    Extract text from an image file or a selected region on the screen.\n",
    "    :param image_path: Path to the image file (optional).\n",
    "    :param region: Tuple (x, y, width, height) for a screen region (optional).\n",
    "    :return: Extracted text as a string.\n",
    "    \"\"\"\n",
    "    if image_path:\n",
    "        # Load image from file\n",
    "        img = Image.open(image_path)\n",
    "    elif region:\n",
    "        # Capture specific region on the screen\n",
    "        screenshot = pyautogui.screenshot(region=region)\n",
    "        screenshot.save(\"selected_region.png\")\n",
    "        img = Image.open(\"selected_region.png\")\n",
    "    else:\n",
    "        raise ValueError(\"Either image_path or region must be provided.\")\n",
    "\n",
    "    # Extract text using Tesseract\n",
    "    extracted_text = pytesseract.image_to_string(img)\n",
    "    return extracted_text\n",
    "\n",
    "\n",
    "# --- Case 2: Extract Tables from PDF ---\n",
    "def extract_tables_from_pdf(pdf_path, page_number=None):\n",
    "    \"\"\"\n",
    "    Extract tables from a PDF file and save them to CSV.\n",
    "    :param pdf_path: Path to the PDF file.\n",
    "    :param page_number: Specific page number to extract tables from (optional).\n",
    "    :return: List of table data (or CSV files saved).\n",
    "    \"\"\"\n",
    "    if page_number:\n",
    "        tables = camelot.read_pdf(pdf_path, pages=str(page_number))\n",
    "    else:\n",
    "        tables = camelot.read_pdf(pdf_path, pages='all')\n",
    "\n",
    "    if not tables:\n",
    "        return \"No tables found in the specified PDF.\"\n",
    "\n",
    "    # Save each table to a CSV file\n",
    "    for i, table in enumerate(tables):\n",
    "        table.to_csv(f\"table_{i + 1}.csv\")\n",
    "\n",
    "    return f\"Extracted {len(tables)} table(s) and saved to CSV.\"\n",
    "\n",
    "\n",
    "# --- Main Program ---\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Choose an option:\")\n",
    "    print(\"1. Extract Text from Image\")\n",
    "    print(\"2. Extract Tabular Data\")\n",
    "\n",
    "    choice = input(\"Enter your choice (1 or 2): \")\n",
    "\n",
    "    if choice == \"1\":\n",
    "        # Case 1: Extract Text from Image\n",
    "        image_path = input(\"Upload an image file (enter the file path): \")\n",
    "        print(\"\\nChoose an option:\")\n",
    "        print(\"1. Extract text from the entire image\")\n",
    "        print(\"2. Select a specific region\")\n",
    "\n",
    "        sub_choice = input(\"Enter your choice (1 or 2): \")\n",
    "\n",
    "        if sub_choice == \"1\":\n",
    "            # Extract text from the entire image\n",
    "            text = extract_text_from_image(image_path=image_path)\n",
    "            print(\"\\nExtracted Text:\\n\", text)\n",
    "        elif sub_choice == \"2\":\n",
    "            # Select a specific region\n",
    "            print(\"Drag and select an area on the screen (example region: x=100, y=100, width=500, height=300).\")\n",
    "            x, y, width, height = map(int, input(\"Enter x, y, width, height: \").split())\n",
    "            text = extract_text_from_image(region=(x, y, width, height))\n",
    "            print(\"\\nExtracted Text from Selected Region:\\n\", text)\n",
    "        else:\n",
    "            print(\"Invalid choice.\")\n",
    "\n",
    "    elif choice == \"2\":\n",
    "        # Case 2: Extract Tabular Data\n",
    "        pdf_path = input(\"Upload a PDF file (enter the file path): \")\n",
    "        print(\"\\nChoose an option:\")\n",
    "        print(\"1. Extract all tables\")\n",
    "        print(\"2. Extract tables from a specific page\")\n",
    "\n",
    "        sub_choice = input(\"Enter your choice (1 or 2): \")\n",
    "\n",
    "        if sub_choice == \"1\":\n",
    "            # Extract all tables\n",
    "            result = extract_tables_from_pdf(pdf_path)\n",
    "            print(result)\n",
    "        elif sub_choice == \"2\":\n",
    "            # Extract tables from a specific page\n",
    "            page_number = int(input(\"Enter the page number: \"))\n",
    "            result = extract_tables_from_pdf(pdf_path, page_number=page_number)\n",
    "            print(result)\n",
    "        else:\n",
    "            print(\"Invalid choice.\")\n",
    "    else:\n",
    "        print(\"Invalid choice. Please restart the program.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e53596ca-7783-4e4f-bf0b-e459f267330e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose an option:\n",
      "1. Extract Text from Image\n",
      "2. Extract Tabular Data\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your choice (1 or 2):  1\n",
      "Upload an image file (enter the file path):  C:\\test2.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Choose an option:\n",
      "1. Extract text from the entire image\n",
      "2. Select a specific region\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your choice (1 or 2):  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please select a region on the image by dragging the mouse.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'end_x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 142\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m sub_choice \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;66;03m# Select a specific region\u001b[39;00m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease select a region on the image by dragging the mouse.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 142\u001b[0m     region \u001b[38;5;241m=\u001b[39m \u001b[43mselect_region_from_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    143\u001b[0m     text \u001b[38;5;241m=\u001b[39m extract_text_from_image(image_path\u001b[38;5;241m=\u001b[39mimage_path, region\u001b[38;5;241m=\u001b[39mregion)\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mExtracted Text from Selected Region:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, text)\n",
      "Cell \u001b[1;32mIn[1], line 92\u001b[0m, in \u001b[0;36mselect_region_from_image\u001b[1;34m(image_path)\u001b[0m\n\u001b[0;32m     89\u001b[0m root\u001b[38;5;241m.\u001b[39mmainloop()\n\u001b[0;32m     91\u001b[0m \u001b[38;5;66;03m# Return the coordinates of the selected region\u001b[39;00m\n\u001b[1;32m---> 92\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (start_x, start_y, \u001b[38;5;28mabs\u001b[39m(\u001b[43mend_x\u001b[49m \u001b[38;5;241m-\u001b[39m start_x), \u001b[38;5;28mabs\u001b[39m(end_y \u001b[38;5;241m-\u001b[39m start_y))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'end_x' is not defined"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "from PIL import Image, ImageTk\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import pyautogui\n",
    "import camelot\n",
    "\n",
    "# Path to Tesseract OCR executable (update this based on your system)\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "\n",
    "# --- Case 1: Extract Text from Image ---\n",
    "def extract_text_from_image(image_path=None, region=None):\n",
    "    \"\"\"\n",
    "    Extract text from an image file or a selected region on the screen.\n",
    "    :param image_path: Path to the image file (optional).\n",
    "    :param region: Tuple (x, y, width, height) for a screen region (optional).\n",
    "    :return: Extracted text as a string.\n",
    "    \"\"\"\n",
    "    if image_path:\n",
    "        # Load image from file\n",
    "        img = Image.open(image_path)\n",
    "    elif region:\n",
    "        # Capture specific region on the screen\n",
    "        screenshot = pyautogui.screenshot(region=region)\n",
    "        screenshot.save(\"selected_region.png\")\n",
    "        img = Image.open(\"selected_region.png\")\n",
    "    else:\n",
    "        raise ValueError(\"Either image_path or region must be provided.\")\n",
    "\n",
    "    # Extract text using Tesseract\n",
    "    extracted_text = pytesseract.image_to_string(img)\n",
    "    return extracted_text\n",
    "\n",
    "\n",
    "# --- Case 1: Select a Region from Image using Tkinter ---\n",
    "def select_region_from_image(image_path):\n",
    "    \"\"\"\n",
    "    Open an image using Tkinter and allow the user to drag to select a region.\n",
    "    :param image_path: Path to the image file.\n",
    "    :return: The coordinates of the selected region (x, y, width, height).\n",
    "    \"\"\"\n",
    "    # Load the image\n",
    "    img = Image.open(image_path)\n",
    "    img = img.resize((600, 400))  # Resize image for easier viewing\n",
    "\n",
    "    # Create Tkinter window\n",
    "    root = tk.Tk()\n",
    "    root.title(\"Select Region\")\n",
    "    \n",
    "    # Convert the image to a Tkinter-compatible format\n",
    "    tk_img = ImageTk.PhotoImage(img)\n",
    "    \n",
    "    # Create a canvas to display the image\n",
    "    canvas = tk.Canvas(root, width=img.width, height=img.height)\n",
    "    canvas.pack()\n",
    "\n",
    "    # Display the image on the canvas\n",
    "    canvas.create_image(0, 0, anchor=\"nw\", image=tk_img)\n",
    "\n",
    "    # Variables to store the coordinates of the rectangle\n",
    "    start_x = start_y = None\n",
    "    rect = None\n",
    "\n",
    "    def on_press(event):\n",
    "        \"\"\"Record the starting point of the rectangle\"\"\"\n",
    "        nonlocal start_x, start_y, rect\n",
    "        start_x, start_y = event.x, event.y\n",
    "        rect = canvas.create_rectangle(start_x, start_y, start_x, start_y, outline=\"red\")\n",
    "\n",
    "    def on_drag(event):\n",
    "        \"\"\"Update the rectangle's end coordinates while dragging\"\"\"\n",
    "        nonlocal rect\n",
    "        canvas.coords(rect, start_x, start_y, event.x, event.y)\n",
    "\n",
    "    def on_release(event):\n",
    "        \"\"\"Finalize the rectangle and return the coordinates\"\"\"\n",
    "        nonlocal start_x, start_y, rect\n",
    "        end_x, end_y = event.x, event.y\n",
    "        root.quit()  # Close the window\n",
    "        return (start_x, start_y, abs(end_x - start_x), abs(end_y - start_y))\n",
    "\n",
    "    # Bind mouse events\n",
    "    canvas.bind(\"<ButtonPress-1>\", on_press)\n",
    "    canvas.bind(\"<B1-Motion>\", on_drag)\n",
    "    canvas.bind(\"<ButtonRelease-1>\", on_release)\n",
    "\n",
    "    # Start Tkinter main loop\n",
    "    root.mainloop()\n",
    "\n",
    "    # Return the coordinates of the selected region\n",
    "    return (start_x, start_y, abs(end_x - start_x), abs(end_y - start_y))\n",
    "\n",
    "\n",
    "# --- Case 2: Extract Tables from PDF ---\n",
    "def extract_tables_from_pdf(pdf_path, page_number=None):\n",
    "    \"\"\"\n",
    "    Extract tables from a PDF file and save them to CSV.\n",
    "    :param pdf_path: Path to the PDF file.\n",
    "    :param page_number: Specific page number to extract tables from (optional).\n",
    "    :return: List of table data (or CSV files saved).\n",
    "    \"\"\"\n",
    "    if page_number:\n",
    "        tables = camelot.read_pdf(pdf_path, pages=str(page_number))\n",
    "    else:\n",
    "        tables = camelot.read_pdf(pdf_path, pages='all')\n",
    "\n",
    "    if not tables:\n",
    "        return \"No tables found in the specified PDF.\"\n",
    "\n",
    "    # Save each table to a CSV file\n",
    "    for i, table in enumerate(tables):\n",
    "        table.to_csv(f\"table_{i + 1}.csv\")\n",
    "\n",
    "    return f\"Extracted {len(tables)} table(s) and saved to CSV.\"\n",
    "\n",
    "\n",
    "# --- Main Program ---\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Choose an option:\")\n",
    "    print(\"1. Extract Text from Image\")\n",
    "    print(\"2. Extract Tabular Data\")\n",
    "\n",
    "    choice = input(\"Enter your choice (1 or 2): \")\n",
    "\n",
    "    if choice == \"1\":\n",
    "        # Case 1: Extract Text from Image\n",
    "        image_path = input(\"Upload an image file (enter the file path): \")\n",
    "        print(\"\\nChoose an option:\")\n",
    "        print(\"1. Extract text from the entire image\")\n",
    "        print(\"2. Select a specific region\")\n",
    "\n",
    "        sub_choice = input(\"Enter your choice (1 or 2): \")\n",
    "\n",
    "        if sub_choice == \"1\":\n",
    "            # Extract text from the entire image\n",
    "            text = extract_text_from_image(image_path=image_path)\n",
    "            print(\"\\nExtracted Text:\\n\", text)\n",
    "        elif sub_choice == \"2\":\n",
    "            # Select a specific region\n",
    "            print(\"Please select a region on the image by dragging the mouse.\")\n",
    "            region = select_region_from_image(image_path)\n",
    "            text = extract_text_from_image(image_path=image_path, region=region)\n",
    "            print(\"\\nExtracted Text from Selected Region:\\n\", text)\n",
    "        else:\n",
    "            print(\"Invalid choice.\")\n",
    "\n",
    "    elif choice == \"2\":\n",
    "        # Case 2: Extract Tabular Data\n",
    "        pdf_path = input(\"Upload a PDF file (enter the file path): \")\n",
    "        print(\"\\nChoose an option:\")\n",
    "        print(\"1. Extract all tables\")\n",
    "        print(\"2. Extract tables from a specific page\")\n",
    "\n",
    "        sub_choice = input(\"Enter your choice (1 or 2): \")\n",
    "\n",
    "        if sub_choice == \"1\":\n",
    "            # Extract all tables\n",
    "            result = extract_tables_from_pdf(pdf_path)\n",
    "            print(result)\n",
    "        elif sub_choice == \"2\":\n",
    "            # Extract tables from a specific page\n",
    "            page_number = int(input(\"Enter the page number: \"))\n",
    "            result = extract_tables_from_pdf(pdf_path, page_number=page_number)\n",
    "            print(result)\n",
    "        else:\n",
    "            print(\"Invalid choice.\")\n",
    "    else:\n",
    "        print(\"Invalid choice. Please restart the program.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c96fe2bc-b46f-4167-8952-7c0bfb03330b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose an option:\n",
      "1. Extract Text from Image\n",
      "2. Extract Tabular Data\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your choice (1 or 2):  1\n",
      "Upload an image file (enter the file path):  C:\\test2.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Choose an option:\n",
      "1. Extract text from the entire image\n",
      "2. Select a specific region\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your choice (1 or 2):  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please select a region on the image by dragging the mouse.\n",
      "\n",
      "Extracted Text from Selected Region:\n",
      " Tomorrow, and\n",
      "â€˜tomorrow, and\n",
      "tomorrow; creeps\n",
      "in this petty pace\n",
      "from day to day,\n",
      "until the last syll-\n",
      "able of recorded\n",
      "time. And all our\n",
      "yesterdays have\n",
      "lighted fools the\n",
      "way to dusty\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "from PIL import Image, ImageTk\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import pyautogui\n",
    "import camelot\n",
    "\n",
    "# Path to Tesseract OCR executable (update this based on your system)\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "\n",
    "# --- Case 1: Extract Text from Image ---\n",
    "def extract_text_from_image(image_path=None, region=None):\n",
    "    \"\"\"\n",
    "    Extract text from an image file or a selected region on the screen.\n",
    "    :param image_path: Path to the image file (optional).\n",
    "    :param region: Tuple (x, y, width, height) for a screen region (optional).\n",
    "    :return: Extracted text as a string.\n",
    "    \"\"\"\n",
    "    if image_path:\n",
    "        # Load image from file\n",
    "        img = Image.open(image_path)\n",
    "    elif region:\n",
    "        # Capture specific region on the screen\n",
    "        screenshot = pyautogui.screenshot(region=region)\n",
    "        screenshot.save(\"selected_region.png\")\n",
    "        img = Image.open(\"selected_region.png\")\n",
    "    else:\n",
    "        raise ValueError(\"Either image_path or region must be provided.\")\n",
    "\n",
    "    # Extract text using Tesseract\n",
    "    extracted_text = pytesseract.image_to_string(img)\n",
    "    return extracted_text\n",
    "\n",
    "\n",
    "# --- Case 1: Select a Region from Image using Tkinter ---\n",
    "def select_region_from_image(image_path):\n",
    "    \"\"\"\n",
    "    Open an image using Tkinter and allow the user to drag to select a region.\n",
    "    :param image_path: Path to the image file.\n",
    "    :return: The coordinates of the selected region (x, y, width, height).\n",
    "    \"\"\"\n",
    "    # Load the image\n",
    "    img = Image.open(image_path)\n",
    "    img = img.resize((600, 400))  # Resize image for easier viewing\n",
    "\n",
    "    # Create Tkinter window\n",
    "    root = tk.Tk()\n",
    "    root.title(\"Select Region\")\n",
    "    \n",
    "    # Convert the image to a Tkinter-compatible format\n",
    "    tk_img = ImageTk.PhotoImage(img)\n",
    "    \n",
    "    # Create a canvas to display the image\n",
    "    canvas = tk.Canvas(root, width=img.width, height=img.height)\n",
    "    canvas.pack()\n",
    "\n",
    "    # Display the image on the canvas\n",
    "    canvas.create_image(0, 0, anchor=\"nw\", image=tk_img)\n",
    "\n",
    "    # Variables to store the coordinates of the rectangle\n",
    "    start_x = start_y = None\n",
    "    end_x = end_y = None\n",
    "    rect = None\n",
    "\n",
    "    def on_press(event):\n",
    "        \"\"\"Record the starting point of the rectangle\"\"\"\n",
    "        nonlocal start_x, start_y, rect\n",
    "        start_x, start_y = event.x, event.y\n",
    "        rect = canvas.create_rectangle(start_x, start_y, start_x, start_y, outline=\"red\")\n",
    "\n",
    "    def on_drag(event):\n",
    "        \"\"\"Update the rectangle's end coordinates while dragging\"\"\"\n",
    "        nonlocal rect\n",
    "        canvas.coords(rect, start_x, start_y, event.x, event.y)\n",
    "\n",
    "    def on_release(event):\n",
    "        \"\"\"Finalize the rectangle and return the coordinates\"\"\"\n",
    "        nonlocal start_x, start_y, end_x, end_y\n",
    "        end_x, end_y = event.x, event.y\n",
    "        root.quit()  # Close the window\n",
    "\n",
    "    # Bind mouse events\n",
    "    canvas.bind(\"<ButtonPress-1>\", on_press)\n",
    "    canvas.bind(\"<B1-Motion>\", on_drag)\n",
    "    canvas.bind(\"<ButtonRelease-1>\", on_release)\n",
    "\n",
    "    # Start Tkinter main loop\n",
    "    root.mainloop()\n",
    "\n",
    "    # Return the coordinates of the selected region\n",
    "    return (start_x, start_y, abs(end_x - start_x), abs(end_y - start_y))\n",
    "\n",
    "\n",
    "# --- Case 2: Extract Tables from PDF ---\n",
    "def extract_tables_from_pdf(pdf_path, page_number=None):\n",
    "    \"\"\"\n",
    "    Extract tables from a PDF file and save them to CSV.\n",
    "    :param pdf_path: Path to the PDF file.\n",
    "    :param page_number: Specific page number to extract tables from (optional).\n",
    "    :return: List of table data (or CSV files saved).\n",
    "    \"\"\"\n",
    "    if page_number:\n",
    "        tables = camelot.read_pdf(pdf_path, pages=str(page_number))\n",
    "    else:\n",
    "        tables = camelot.read_pdf(pdf_path, pages='all')\n",
    "\n",
    "    if not tables:\n",
    "        return \"No tables found in the specified PDF.\"\n",
    "\n",
    "    # Save each table to a CSV file\n",
    "    for i, table in enumerate(tables):\n",
    "        table.to_csv(f\"table_{i + 1}.csv\")\n",
    "\n",
    "    return f\"Extracted {len(tables)} table(s) and saved to CSV.\"\n",
    "\n",
    "\n",
    "# --- Main Program ---\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Choose an option:\")\n",
    "    print(\"1. Extract Text from Image\")\n",
    "    print(\"2. Extract Tabular Data\")\n",
    "\n",
    "    choice = input(\"Enter your choice (1 or 2): \")\n",
    "\n",
    "    if choice == \"1\":\n",
    "        # Case 1: Extract Text from Image\n",
    "        image_path = input(\"Upload an image file (enter the file path): \")\n",
    "        print(\"\\nChoose an option:\")\n",
    "        print(\"1. Extract text from the entire image\")\n",
    "        print(\"2. Select a specific region\")\n",
    "\n",
    "        sub_choice = input(\"Enter your choice (1 or 2): \")\n",
    "\n",
    "        if sub_choice == \"1\":\n",
    "            # Extract text from the entire image\n",
    "            text = extract_text_from_image(image_path=image_path)\n",
    "            print(\"\\nExtracted Text:\\n\", text)\n",
    "        elif sub_choice == \"2\":\n",
    "            # Select a specific region\n",
    "            print(\"Please select a region on the image by dragging the mouse.\")\n",
    "            region = select_region_from_image(image_path)\n",
    "            text = extract_text_from_image(image_path=image_path, region=region)\n",
    "            print(\"\\nExtracted Text from Selected Region:\\n\", text)\n",
    "        else:\n",
    "            print(\"Invalid choice.\")\n",
    "\n",
    "    elif choice == \"2\":\n",
    "        # Case 2: Extract Tabular Data\n",
    "        pdf_path = input(\"Upload a PDF file (enter the file path): \")\n",
    "        print(\"\\nChoose an option:\")\n",
    "        print(\"1. Extract all tables\")\n",
    "        print(\"2. Extract tables from a specific page\")\n",
    "\n",
    "        sub_choice = input(\"Enter your choice (1 or 2): \")\n",
    "\n",
    "        if sub_choice == \"1\":\n",
    "            # Extract all tables\n",
    "            result = extract_tables_from_pdf(pdf_path)\n",
    "            print(result)\n",
    "        elif sub_choice == \"2\":\n",
    "            # Extract tables from a specific page\n",
    "            page_number = int(input(\"Enter the page number: \"))\n",
    "            result = extract_tables_from_pdf(pdf_path, page_number=page_number)\n",
    "            print(result)\n",
    "        else:\n",
    "            print(\"Invalid choice.\")\n",
    "    else:\n",
    "        print(\"Invalid choice. Please restart the program.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0469ce48-709f-42d6-bdca-aab67b655180",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
